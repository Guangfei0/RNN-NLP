{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.contrib.rnn import static_rnn as get_rnn_output\n",
    "from tensorflow.contrib.rnn import BasicRNNCell, GRUCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(split_sequences = False):\n",
    "    word2idx = {}\n",
    "    tag2idx = {}\n",
    "    word_idx = 1\n",
    "    tag_idx = 1\n",
    "    Xtrain = []\n",
    "    Ytrain = []\n",
    "    currentX = []\n",
    "    currentY = []\n",
    "    for line in open('ner.txt'):\n",
    "        line = line.rstrip()\n",
    "        if line:\n",
    "            r = line.split()\n",
    "            word, tag = r\n",
    "            word = word.lower()\n",
    "            if word not in word2idx:\n",
    "                word2idx[word] = word_idx\n",
    "                word_idx += 1 \n",
    "            currentX.append(word2idx[word])\n",
    "            \n",
    "            if tag not in word2idx:\n",
    "                tag2idx[tag] = tag_idx\n",
    "                tag_idx += 1 \n",
    "            currentY.append(tag2idx[tag])\n",
    "        \n",
    "        elif split_sequences:\n",
    "            Xtrain.append(currentX)\n",
    "            Ytrain.append(currentY)\n",
    "            currentX = []\n",
    "            currentY = []\n",
    "    \n",
    "    if not split_sequences:\n",
    "        Xtrain = currentX\n",
    "        Ytrain = currentY\n",
    "        \n",
    "    print(\"number of samples:\", len(Xtrain))\n",
    "    Xtrain, Ytrain = shuffle(Xtrain, Ytrain)\n",
    "    Ntest = int(0.3*len(Xtrain))\n",
    "    Xtest = Xtrain[:Ntest]\n",
    "    Ytest = Ytrain[:Ntest]\n",
    "    Xtrain = Xtrain[Ntest:]\n",
    "    Ytrain = Ytrain[Ntest:]\n",
    "    print(\"number of classes:\", len(tag2idx))\n",
    "    return Xtrain, Ytrain, Xtest, Ytest, word2idx, tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 2394\n",
      "number of classes: 21\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Ytrain, Xtest, Ytest, word2idx, tag2idx = get_data(split_sequences = True)\n",
    "V = len(word2idx) + 2 # +1 for unknown, +1 for padding 0\n",
    "K = len(set(flatten(Ytrain)) | set(flatten(Ytest))) + 1 # +1 for padding 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "learning_rate = 1e-2\n",
    "mu = 0.99\n",
    "batch_size = 32\n",
    "hidden_layer_size = 10\n",
    "embedding_dim = 10\n",
    "sequence_length = max(len(x) for x in Xtrain + Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain.shape: (1676, 39)\n",
      "Ytrain.shape: (1676, 39)\n"
     ]
    }
   ],
   "source": [
    "Xtrain = tf.keras.preprocessing.sequence.pad_sequences(Xtrain, maxlen = sequence_length)\n",
    "Ytrain = tf.keras.preprocessing.sequence.pad_sequences(Ytrain, maxlen = sequence_length)\n",
    "Xtest = tf.keras.preprocessing.sequence.pad_sequences(Xtest, maxlen = sequence_length)\n",
    "Ytest = tf.keras.preprocessing.sequence.pad_sequences(Ytest, maxlen = sequence_length)\n",
    "print(\"Xtrain.shape:\", Xtrain.shape)\n",
    "print(\"Ytrain.shape:\", Ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.int32, shape = (None, sequence_length))\n",
    "targets = tf.placeholder(tf.int32, shape = (None, sequence_length))\n",
    "num_samples = tf.shape(inputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We = np.random.randn(V, embedding_dim).astype(np.float32)\n",
    "Wo = np.random.randn(hidden_layer_size, K)/np.sqrt(hidden_layer_size + K)\n",
    "Wo = Wo.astype(np.float32)\n",
    "bo = np.zeros(K).astype(np.float32)\n",
    "tfWe = tf.Variable(We)\n",
    "tfWo = tf.Variable(Wo)\n",
    "tfbo = tf.Variable(bo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_unit = GRUCell(num_units=hidden_layer_size, activation=tf.nn.relu)\n",
    "x = tf.nn.embedding_lookup(tfWe, inputs)\n",
    "x = tf.unstack(x, sequence_length, 1)\n",
    "outputs, states = get_rnn_output(rnn_unit, x, dtype=tf.float32)\n",
    "outputs = tf.transpose(outputs, (1, 0, 2))\n",
    "outputs = tf.reshape(outputs, (sequence_length*num_samples, hidden_layer_size)) # NT x M\n",
    "logits = tf.matmul(outputs, tfWo) + tfbo # NT x K\n",
    "predictions = tf.argmax(logits, 1)\n",
    "predict_op = tf.reshape(predictions, (num_samples, sequence_length)) # N x T\n",
    "labels_flat = tf.reshape(targets, [-1]) # NT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_op = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits = logits,\n",
    "        labels = labels_flat\n",
    "    )\n",
    ")\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0 cost: 346.3824 train acc: 0.0000 test acc: 0.0000 time for epoch: 0:01:54.228401\n",
      "i: 1 cost: 274.0212 train acc: 0.0000 test acc: 0.0000 time for epoch: 0:01:46.477832\n",
      "i: 2 cost: 263.3712 train acc: 0.0000 test acc: 0.0000 time for epoch: 0:01:50.897552\n",
      "j/N: 50/52 correct rate so far: 0.000189, cost so far: 241.236607\r"
     ]
    }
   ],
   "source": [
    "costs = []\n",
    "n_batches = len(Ytrain) // batch_size\n",
    "for i in range(epochs):\n",
    "    n_total = 0 \n",
    "    n_correct = 0\n",
    "    \n",
    "    t0 = datetime.now()\n",
    "    Xtrain, Ytrain = shuffle(Xtrain, Ytrain)\n",
    "    cost = 0 \n",
    "    \n",
    "    for j in range(n_batches):\n",
    "        x = Xtrain[j*batch_size:(j+1)*batch_size]\n",
    "        y = Ytrain[j*batch_size:(j+1)*batch_size]\n",
    "        \n",
    "        c, p, _ = sess.run(\n",
    "            (cost_op, predict_op, train_op),\n",
    "            feed_dict = {inputs: x, targets: y}\n",
    "        ) # p: N x T   y: N x T\n",
    "        cost += c\n",
    "        \n",
    "        for yi, pi in zip(y, p):\n",
    "            yii = yi[yi > 0]\n",
    "            pii = pi[yi > 0]\n",
    "            n_correct += np.sum(yii == pii)\n",
    "            n_total += len(yii)\n",
    "        \n",
    "        if j % 10 == 0:\n",
    "            sys.stdout.write(\n",
    "                \"j/N: %d/%d correct rate so far: %f, cost so far: %f\\r\" %\n",
    "                (j, n_batches, float(n_correct)/n_total, cost)\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "    p = sess.run(predict_op, feed_dict = {inputs: Xtest, targets: Ytest})\n",
    "    n_test_correct = 0 \n",
    "    n_test_total = 0 \n",
    "    for yi, pi in zip(Ytest, p):\n",
    "        yii = yi[yi > 0]\n",
    "        pii = pi[yi > 0]\n",
    "        n_test_correct += np.sum(yii == pii)\n",
    "        n_test_total += len(yii)\n",
    "    test_acc = float(n_test_correct) / n_test_total\n",
    "    \n",
    "    print(\n",
    "        \"i:\", i, \"cost:\", \"%.4f\" % cost,\n",
    "        \"train acc:\", \"%.4f\" % (float(n_correct)/n_total),\n",
    "        \"test acc:\", \"%.4f\" % test_acc,\n",
    "        \"time for epoch:\", (datetime.now() - t0)\n",
    "    )\n",
    "    costs.append(cost)\n",
    "\n",
    "plt.plot(costs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
